{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import sqrt, float32, array\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import cv2\n",
    "import tensorflow.python.platform\n",
    "from keras.preprocessing import sequence\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! pip list --uptodate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = '../save_model_final'\n",
    "model_path_transfer = '../save_model_final'\n",
    "# feature_path = '../data/feats.npy'\n",
    "# annotation_path_kr = '../data/korean_data/ko_translateGoogle_caption.txt'\n",
    "feature_path = '../test0607.txt' #벡터화된 키워드\n",
    "annotation_path_kr = '../para0607.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(annotation_path_kr, feature_path):\n",
    "    with open('para0607.txt', 'rb') as f:\n",
    "        captions = np.array(pickle.load(f))\n",
    "        # captions = pickle.load(f)\n",
    "        # captions = captions[0:100]\n",
    "    with open('test0607.txt', 'rb') as f:\n",
    "        feats = np.array(pickle.load(f))\n",
    "        # feats = pickle.load(f)\n",
    "        # feats = feats[0:100]\n",
    "        \n",
    "    return feats, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle에 저장하기\n",
    "# with open('sentence.txt', 'wb') as f:\n",
    "#     pickle.dump(sentence, f)\n",
    "# f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data load\n",
    "feats, captions = get_data(annotation_path_kr, feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12360, 2000)\n",
      "(12360,)\n",
      "평소 CM에 관심이 있던 후배, 동기와 함께 팀을 이루어 공모전에 참여했습니다. 총 6명이 한 조를 이루었고 저는 리더를 맡았습니다. 상황이 좋지 않았습니다. 부지선정부터 공법선정 등 준비해야 할 범위가 너무 컸으며 더불어 시험과 과제제출 등이 겹치면서 준비에 어려움이 있었습니다. 저는 리더로서 두 가지 방법을 제안하여 문제를 해결하고자 했습니다. 흥미에 맞는 분야를 담당: 열정적으로 과업을 수행하도록 했습니다. 피드백 모임- 개인이 미처 보지 못한 부분을 점검하도록 했습니다. 그 외에도 팀원끼리 지속해서 연락하여 서로 모르는 부분을 채워가며 공모전을 준비했습니다. 그 결과 바쁜 일정 와중에도 모두가 만족하는 작품을 완성할 수 있었습니다. 비록, 순위에는 들지 못했지만, 사업 전반을 계획해보고 공사의 흐름을 파악할 수 있었던 값진 경험이었습니다. 이 경험을 통해 구성원 간 소통의 중요성과 협업을 통해 난관을 이겨내는 법을 배웠습니다. 다수의 업체와 협력이 이루어지는 건설 현장에서 소통을 통해 갈등을 유연하게 해결하고 협력을 통해 효율적으로 목표를 달성하겠습니다.\n",
      "[ 0.724064   -0.5830169   0.00841407 ... -0.24805881  0.2740903\n",
      " -0.49066275]\n"
     ]
    }
   ],
   "source": [
    "# 확인\n",
    "print(feats.shape) #임베딩 백터\n",
    "print(captions.shape) #문장\n",
    "print(captions[1])\n",
    "print(feats[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProBuildWordVocab(sentence_iterator, word_count_threshold=20): # function from Andre Karpathy's NeuralTalk\n",
    "    print('preprocessing %d word vocab' % (word_count_threshold, ))\n",
    "    word_counts = {}\n",
    "    nsents = 0\n",
    "    for sent in sentence_iterator:\n",
    "        nsents += 1\n",
    "        for w in sent.lower().split(' '):\n",
    "            word_counts[w] = word_counts.get(w, 0) + 1\n",
    "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "    print('preprocessed words %d -> %d' % (len(word_counts), len(vocab)))\n",
    "\n",
    "    ixtoword = {}\n",
    "    ixtoword[0] = '.'  \n",
    "    wordtoix = {}\n",
    "    wordtoix['#START#'] = 0 \n",
    "    ix = 1\n",
    "    for w in vocab:\n",
    "        wordtoix[w] = ix\n",
    "        ixtoword[ix] = w\n",
    "        ix += 1\n",
    "\n",
    "    word_counts['.'] = nsents\n",
    "    bias_init_vector = np.array([1.0*word_counts[ixtoword[i]] for i in ixtoword])\n",
    "    bias_init_vector /= np.sum(bias_init_vector) \n",
    "    bias_init_vector = np.log(bias_init_vector)\n",
    "    bias_init_vector -= np.max(bias_init_vector)\n",
    "    \n",
    "    return wordtoix, ixtoword, bias_init_vector.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Caption_Generator():\n",
    "    def __init__(self, dim_in, dim_embed, dim_hidden, batch_size, n_lstm_steps, n_words, init_b):\n",
    "        \n",
    "        self.dim_in = dim_in\n",
    "        self.dim_embed = dim_embed\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.batch_size = batch_size\n",
    "        self.n_lstm_steps = n_lstm_steps\n",
    "        self.n_words = n_words\n",
    "        \n",
    "        # declare the variables to be used for our word embeddings\n",
    "        with tf.device(\"/cpu:0\"): # tf.device(\"/cpu:0\"):\n",
    "            self.word_embedding = tf.Variable(tf.random_uniform([self.n_words, self.dim_embed], -0.1, 0.1), name='word_embedding')\n",
    "            \n",
    "        self.embedding_bias = tf.Variable(tf.zeros([self.dim_embed]), name='embedding_bias')\n",
    "        \n",
    "        # declare the LSTM itself\n",
    "        # self.lstm = tf.contrib.rnn.BasicLSTMCell(dim_hidden, state_is_tuple=True)\n",
    "        \n",
    "        \n",
    "        ########## multi-layer ##########\n",
    "        def lstm_cell():\n",
    "            cell = tf.contrib.rnn.BasicLSTMCell(dim_hidden, state_is_tuple=True)\n",
    "            return cell\n",
    "\n",
    "        self.lstm = tf.contrib.rnn.MultiRNNCell([lstm_cell() for i in range(3)], state_is_tuple=True)\n",
    "        ################################\n",
    "        \n",
    "        \n",
    "        # declare the variables to be used to embed the image feature embedding to the word embedding space\n",
    "        self.img_embedding = tf.Variable(tf.random_uniform([dim_in, dim_hidden], -0.1, 0.1), name='img_embedding')\n",
    "        self.img_embedding_bias = tf.Variable(tf.zeros([dim_hidden]), name='img_embedding_bias')\n",
    "\n",
    "        # declare the variables to go from an LSTM output to a word encoding output\n",
    "        self.word_encoding = tf.Variable(tf.random_uniform([dim_hidden, n_words], -0.1, 0.1), name='word_encoding')\n",
    "        \n",
    "        # initialize this bias variable from the preProBuildWordVocab output\n",
    "        self.word_encoding_bias = tf.Variable(init_b, name='word_encoding_bias')\n",
    "\n",
    "    def build_model(self):\n",
    "        # declaring the placeholders for our extracted image feature vectors, our caption, and our mask\n",
    "        # (describes how long our caption is with an array of 0/1 values of length `maxlen`  \n",
    "        img = tf.placeholder(tf.float32, [self.batch_size, self.dim_in])\n",
    "        caption_placeholder = tf.placeholder(tf.int32, [self.batch_size, self.n_lstm_steps])\n",
    "        mask = tf.placeholder(tf.float32, [self.batch_size, self.n_lstm_steps])\n",
    "                \n",
    "        # getting an initial LSTM embedding from our image_imbedding\n",
    "        image_embedding = tf.matmul(img, self.img_embedding) + self.img_embedding_bias\n",
    "        # setting initial state of our LSTM\n",
    "        state = self.lstm.zero_state(self.batch_size, dtype=tf.float32)\n",
    "\n",
    "        total_loss = 0.0\n",
    "        with tf.variable_scope(\"RNN\"):\n",
    "            for i in range(self.n_lstm_steps): \n",
    "                if i > 0:\n",
    "                   #if this isn’t the first iteration of our LSTM we need to get the word_embedding corresponding\n",
    "                   # to the (i-1)th word in our caption \n",
    "                    with tf.device(\"/cpu:0\"): # tf.device(\"/cpu:0\"):\n",
    "                        current_embedding = tf.nn.embedding_lookup(self.word_embedding, caption_placeholder[:,i-1]) + self.embedding_bias\n",
    "                else:\n",
    "                     #if this is the first iteration of our LSTM we utilize the embedded image as our input \n",
    "                    current_embedding = image_embedding\n",
    "                if i > 0: \n",
    "                    # allows us to reuse the LSTM tensor variable on each iteration\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                \n",
    "                current_embedding = tf.expand_dims(current_embedding, 1)\n",
    "                out, state = tf.nn.dynamic_rnn(cell=self.lstm, inputs=current_embedding\n",
    "                                                               ,initial_state=state)\n",
    "\n",
    "                if i > 0:\n",
    "                    #get the one-hot representation of the next word in our caption \n",
    "                    labels = tf.expand_dims(caption_placeholder[:, i], 1)\n",
    "                    ix_range = tf.range(0, self.batch_size, 1)\n",
    "                    ixs = tf.expand_dims(ix_range, 1)\n",
    "                    concat = tf.concat([ixs, labels],1)\n",
    "                    onehot = tf.sparse_to_dense(\n",
    "                            concat, tf.stack([self.batch_size, self.n_words]), 1.0, 0.0)\n",
    "\n",
    "                    #perform a softmax classification to generate the next word in the caption\n",
    "                    out = tf.squeeze(out, [1])\n",
    "                    logit = tf.matmul(out, self.word_encoding) + self.word_encoding_bias\n",
    "                    xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=onehot)\n",
    "                    xentropy = xentropy * mask[:,i]\n",
    "\n",
    "                    loss = tf.reduce_sum(xentropy)\n",
    "                    total_loss += loss\n",
    "\n",
    "            total_loss = total_loss / tf.reduce_sum(mask[:,1:])\n",
    "            return total_loss, img,  caption_placeholder, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Parameters ###\n",
    "dim_embed = 50 # dimension of word embedding\n",
    "dim_hidden = 50 # dimension of all hidden state size\n",
    "dim_in = 2000 # input dimension\n",
    "batch_size = 30\n",
    "momentum = 0.9\n",
    "n_epochs = 150\n",
    "\n",
    "def train(learning_rate=0.001, continue_training=False, transfer=True):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    feats, captions = get_data(annotation_path_kr, feature_path)\n",
    "    wordtoix, ixtoword, init_b = preProBuildWordVocab(captions)\n",
    "\n",
    "    np.save('../DJ/data/ixtoword_kr', ixtoword)\n",
    "\n",
    "    index = (np.arange(len(feats)).astype(int))\n",
    "    np.random.shuffle(index)\n",
    "\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    n_words = len(wordtoix)\n",
    "    maxlen = np.max( [x for x in map(lambda x: len(x.split(' ')), captions)] )\n",
    "    \n",
    "    caption_generator = Caption_Generator(dim_in, dim_hidden, dim_embed, batch_size, maxlen+2, n_words, init_b)\n",
    "\n",
    "    \n",
    "    loss, image, sentence, mask = caption_generator.build_model()\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    global_step=tf.Variable(0,trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate, global_step, int(len(index)/batch_size), 0.95)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    if continue_training:\n",
    "        if not transfer:\n",
    "            saver.restore(sess,tf.train.latest_checkpoint(model_path))\n",
    "        else:\n",
    "            saver.restore(sess,tf.train.latest_checkpoint(model_path_transfer))\n",
    "            \n",
    "    losses=[]\n",
    "    for epoch in range(n_epochs):\n",
    "        for start, end in zip( range(0, len(index), batch_size), range(batch_size, len(index), batch_size)):\n",
    "\n",
    "            current_feats = feats[index[start:end]]\n",
    "            current_captions = captions[index[start:end]]\n",
    "            current_caption_ind = [x for x in map(lambda cap: [wordtoix[word] for word in cap.lower().split(' ')[:-1] if word in wordtoix], current_captions)]\n",
    "\n",
    "            current_caption_matrix = sequence.pad_sequences(current_caption_ind, padding='post', maxlen=maxlen+1)\n",
    "            current_caption_matrix = np.hstack( [np.full( (len(current_caption_matrix),1), 0), current_caption_matrix] )\n",
    "\n",
    "            current_mask_matrix = np.zeros((current_caption_matrix.shape[0], current_caption_matrix.shape[1]))\n",
    "            nonzeros = np.array([x for x in map(lambda x: (x != 0).sum()+2, current_caption_matrix )])\n",
    "\n",
    "            for ind, row in enumerate(current_mask_matrix):\n",
    "                row[:nonzeros[ind]] = 1\n",
    "\n",
    "            _, loss_value = sess.run([train_op, loss], feed_dict={\n",
    "                image: current_feats.astype(np.float32),\n",
    "                sentence : current_caption_matrix.astype(np.int32),\n",
    "                mask : current_mask_matrix.astype(np.float32)\n",
    "                })\n",
    "\n",
    "            print(\"Current Cost: \", loss_value, \"\\t Epoch {}/{}\".format(epoch, n_epochs), \"\\t Iter {}/{}\".format(start,len(feats)))\n",
    "        print(\"Saving the model from epoch: \", epoch)\n",
    "        saver.save(sess, os.path.join(model_path, 'model'), global_step=epoch)\n",
    "        losses.append(loss_value)\n",
    "    \n",
    "    # pickle에 저장하기\n",
    "    with open('loss_0607.txt', 'wb') as f:\n",
    "        pickle.dump(losses, f)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing 20 word vocab\n",
      "preprocessed words 208030 -> 10370\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train(.001,False,False)    #train from scratch\n",
    "    #train(.001,True,True)    #continue training from pretrained weights @epoch500\n",
    "    #train(.001,True,False)  #train from previously saved weights\n",
    "except KeyboardInterrupt:\n",
    "    print('Exiting Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('loss_0607.txt', 'rb') as f:\n",
    "        loss = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.998882, 5.9972706]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
